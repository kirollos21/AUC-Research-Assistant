# Application
APP_NAME="AUC Research Assistant"
APP_VERSION=1.0.0
DEBUG=true
ENVIRONMENT=development

# Server
HOST=0.0.0.0
PORT=8000

# AI/ML APIs
OPENAI_API_KEY=your-openai-api-key
OPENAI_ORG_ID=your-openai-org-id

LLM_TEMPERATURE=0.7
LLM_MAX_OUTPUT_TOKENS=2000

# Mistral AI
MISTRAL_API_KEY=your-mistral-api-key
MISTRAL_LLM_MODEL=mistral-medium-latest
EMBEDDING_MODEL=mistral-embed

# Cohere AI (optional - for reranking)
COHERE_API_KEY=your-cohere-api-key

# Semantic Scholar API
# If not set, will proceed without API key (higher rate limits apply)
# SEMANTIC_SCHOLAR_API_KEY=your-key-here

# Embedding Model Configuration
# EMBEDDING_MODE can be 'local' (default) or 'openai'
EMBEDDING_MODE=local

# Settings for 'openai' embedding mode
# You can use a different key for embeddings if needed, otherwise OPENAI_API_KEY will be used
OPENAI_EMBEDDING_API_KEY=your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# Optional: specify a different endpoint for OpenAI-compatible APIs
OPENAI_EMBEDDING_API_ENDPOINT=

# Vector Database
VECTOR_DB_TYPE=chromadb
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# CORS
CORS_ORIGINS='["http://localhost:3000","http://127.0.0.1:3000"]'
CORS_CREDENTIALS=true
CORS_METHODS='["GET","POST","PUT","DELETE","OPTIONS"]'
CORS_HEADERS='["*"]'
