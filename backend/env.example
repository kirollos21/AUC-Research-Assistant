# Application
APP_NAME="AUC Research Assistant"
APP_VERSION=1.0.0
DEBUG=true
ENVIRONMENT=development

# Server
HOST=0.0.0.0
PORT=8000

# Database
DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/auc_research_db
DATABASE_TEST_URL=postgresql+asyncpg://username:password@localhost:5432/auc_research_test_db

# Redis (for caching and task queue)
REDIS_URL=redis://localhost:6379/0

# Security
SECRET_KEY=your-super-secret-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI/ML APIs
OPENAI_API_KEY=your-openai-api-key
OPENAI_ORG_ID=your-openai-org-id

LLM_TEMPERATURE=0.7
LLM_MAX_OUTPUT_TOKENS=2000

# Mistral AI
MISTRAL_API_KEY=your-mistral-api-key
MISTRAL_LLM_MODEL=mistral-medium-latest
MISTRAL_EMBEDDING_MODEL=mistral-embed

# Cohere AI (optional - for reranking)
COHERE_API_KEY=your-cohere-api-key

# Semantic Scholar API
# If not set, will proceed without API key (higher rate limits apply)
# SEMANTIC_SCHOLAR_API_KEY=your-key-here

# Embedding Model Configuration
# EMBEDDING_MODE can be 'local' (default) or 'openai'
EMBEDDING_MODE=local

# Settings for 'openai' embedding mode
# You can use a different key for embeddings if needed, otherwise OPENAI_API_KEY will be used
OPENAI_EMBEDDING_API_KEY=your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# Optional: specify a different endpoint for OpenAI-compatible APIs
OPENAI_EMBEDDING_API_ENDPOINT=

# Vector Database
VECTOR_DB_TYPE=chromadb
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# File Upload
MAX_FILE_SIZE=10485760  # 10MB
UPLOAD_DIRECTORY=./uploads
ALLOWED_EXTENSIONS='["pdf","txt","docx","xlsx","csv"]'

# Logging
LOG_LEVEL=INFO
LOG_FORMAT='%(asctime)s - %(name)s - %(levelname)s - %(message)s'

# CORS
CORS_ORIGINS='["http://localhost:3000","http://127.0.0.1:3000"]'
CORS_CREDENTIALS=true
CORS_METHODS='["GET","POST","PUT","DELETE","OPTIONS"]'
CORS_HEADERS='["*"]'
